{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c76223ce",
   "metadata": {},
   "source": [
    "## Linear Algebra\n",
    "\n",
    "Linear algebra refers to the study of linear relationships. In this class, we will cover some basic concepts of linear algebra that are needed to understand some more advanced and *practical* concepts and definitions. If you are interested in the concepts related to linear algebra and application, there is an excellent online series that covers these topics in detail \n",
    "\n",
    "https://github.com/fastai/numerical-linear-algebra\n",
    "\n",
    "\n",
    "Linear algebra is a fundamental component of machine learning, so if you are interested in using machine learning in the future go and check that class. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25539969",
   "metadata": {},
   "source": [
    "### Vectors\n",
    "\n",
    "A vector is a collection of numbers. Vectors can be **row vectors** or **column vectors** depending on their orientation. In general, you can assume that a vector is a **column vector** unless otherwise stated. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44048487",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 5)\n",
      "(4, 1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "vector_row = np.array([[1, -5, 3, 2, 4]])\n",
    "vector_column = np.array([[1], \n",
    "                          [2], \n",
    "                          [3], \n",
    "                          [4]])\n",
    "print(vector_row.shape)\n",
    "print(vector_column.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156fa70c",
   "metadata": {},
   "source": [
    "The transpose ($T$) of a vector is an operation that transform a column vector into a row vector and a row vector into a column vector. If $v$ is a vector, then $v^{T}$ is the transpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aea1b2e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 1, -5,  3,  2,  4]]),\n",
       " array([[ 1],\n",
       "        [-5],\n",
       "        [ 3],\n",
       "        [ 2],\n",
       "        [ 4]]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_row, vector_row.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127ff6ba",
   "metadata": {},
   "source": [
    "The norm of a vector is a measure of its lenght. There are many ways to measure lenght and you can use different definitions depending on the application. The most common norm is the $L_2$ norm, if $v$ is a vector, then the $L_2$ norm ($\\Vert v \\Vert_{2}$) is \n",
    "\n",
    "$$\n",
    "\\Vert v \\Vert_{2} = \\sqrt{\\sum_i v_i^2}\n",
    "$$\n",
    "\n",
    "This is also known as the Euclidian norm. \n",
    "\n",
    "Others well known norms are the $L_1$ norm (or Manhattan Distance), and the $L_\\infty$ norm (or infinity norm) equal to the maximum absolut value of the vector "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ae203a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L_1 is: 15.0\n",
      "L_2 is: 7.4\n",
      "L_inf is: 5.0\n"
     ]
    }
   ],
   "source": [
    "from numpy.linalg import norm\n",
    "new_vector = vector_row.T\n",
    "norm_1 = norm(new_vector, 1)\n",
    "norm_2 = norm(new_vector, 2)\n",
    "norm_inf = norm(new_vector, np.inf)\n",
    "print('L_1 is: %.1f'%norm_1)\n",
    "print('L_2 is: %.1f'%norm_2)\n",
    "print('L_inf is: %.1f'%norm_inf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69be0a5b",
   "metadata": {},
   "source": [
    "The **dot product**  of two vectors is the sum of the product of the respective elements in each vector and is denoted by $\\cdot$. If $v$ and $w$ are vectors, then the dot product is defined as \n",
    "$$\n",
    "d = v \\cdot w= \\sum_{i = 1}^{n} v_iw_i\n",
    "$$\n",
    "\n",
    "alternatively, the dot product can be computed as \n",
    "\n",
    "$$\n",
    "v \\cdot w = \\Vert v \\Vert_{2} \\Vert w \\Vert_{2} \\cos{\\theta}\n",
    "$$\n",
    "\n",
    "where $\\theta$ is the angle between the vectors. In the same way, the angle between two vector can be computed as \n",
    "\n",
    "$$\n",
    "\\theta = cos^{-1}\\left[\\frac{v \\cdot w }{\\Vert v \\Vert_{2} \\Vert w \\Vert_{2}}\\right]\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e7271749",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8.53773646e-07]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lets take two vectors that are on the same direction but have different lenghts \n",
    "from numpy import arccos, dot\n",
    "v = np.array([[1,2]])\n",
    "w = np.array([[5,10]])\n",
    "theta = arccos(v.dot(w.T)/(norm(v)*norm(w)))\n",
    "theta*(180/pi) #arcos return gradients, we are convering to degrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1bd993f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[179.99999879]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lets take two vectors that are on opposite directions \n",
    "from numpy import arccos, dot, pi\n",
    "v = np.array([[1,2]])\n",
    "w = np.array([[-1,-2]])\n",
    "theta = arccos(v.dot(w.T)/(norm(v)*norm(w)))\n",
    "theta*(180/pi) #arcos return gradients, we are convering to degrees "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "37cbec77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[90.]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lets take two vectors that are on orthogonal to eachother \n",
    "from numpy import arccos, dot, pi\n",
    "v = np.array([[1,1]])\n",
    "w = np.array([[-1,1]])\n",
    "theta = arccos(v.dot(w.T)/(norm(v)*norm(w)))\n",
    "theta*(180/pi) #arcos return gradients, we are convering to degrees "
   ]
  },
  {
   "attachments": {
    "098c028a-6ce4-4452-b428-8b2421a382ff.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "d0e7c113",
   "metadata": {},
   "source": [
    "The **cross product** between two vectors, $v$ and $w$, is written $v\\times w$. It is defined by \n",
    "\n",
    "$$\n",
    "v \\times w = \\Vert v \\Vert_{2}\\Vert w \\Vert_{2}\\sin{(\\theta)} \n",
    "$$\n",
    "\n",
    "where $θ$ is the angle between the $v$ and $w$.\n",
    "\n",
    "The geometric interpretation of the cross product is a vector perpendicular to both $v$ and $w$ with length (as measured by $L_2$) equal to the area enclosed by the parallelogram created by the two vectors.\n",
    "\n",
    "![image.png](attachment:098c028a-6ce4-4452-b428-8b2421a382ff.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2f103505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  0 -6]]\n"
     ]
    }
   ],
   "source": [
    "v = np.array([[0, 2, 0]])\n",
    "w = np.array([[3, 0, 0]])\n",
    "cross = np.cross(v, w)\n",
    "print(cross)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5a22c4d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[90.]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arccos(v.dot(cross.T)/(norm(v)*norm(cross)))*(180/pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "528180e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[90.]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arccos(w.dot(cross.T)/(norm(w)*norm(cross)))*(180/pi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3d0d10",
   "metadata": {},
   "source": [
    "### Matrices \n",
    "\n",
    "An $n \\times m $ matrix is a rectangular table of numbers consisting of $m$ rows and $n$ columns.\n",
    "\n",
    "The norm of a matrix can be consider as a kind of vector norm by alingming the $n * m$ elements of the matrix into a single vector\n",
    "$$\n",
    "\\Vert M \\Vert_{p} = \\sqrt[p]{(\\sum_i^m \\sum_j^n |a_{ij}|^p)}\n",
    "$$\n",
    "\n",
    "where $p$ defines the norm order ($p=0, 1, 2,...$)\n",
    "\n",
    "\n",
    "**Matrix multiplication** between two matrices, $P$ and $Q$, is defined when $P$ is an $m \\timed p$ matrix and $Q$ is a $p \\times n$ matrix. The result of $M=PQ$ is a matrix $M$ that is $m \\times n$. The dimension with size $p$ is called the inner matrix dimension, and the inner matrix dimensions must match (i.e., the number of columns in $P$ and the number of rows in $Q$ must be the same) for matrix multiplication. The dimensions $m$ and $n$ are called the outer matrix dimensions. Formally,  $M=PQ$ is defined as\n",
    "$$\n",
    "M_{ij} = \\sum_{k=1}^p P_{ik}Q_{kj}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bbb3ea5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 7]\n",
      " [2 3]\n",
      " [5 0]]\n",
      "The dimensions of P are: (3, 2)\n",
      "[[2 6 3 1]\n",
      " [1 2 3 4]] (2, 4)\n",
      "The dimensions of Q are: (2, 4)\n",
      "[[ 9 20 24 29]\n",
      " [ 7 18 15 14]\n",
      " [10 30 15  5]]\n",
      "The dimensions of PxQ are: (3, 4)\n"
     ]
    }
   ],
   "source": [
    "P = np.array([[1, 7], [2, 3], [5, 0]])\n",
    "Q = np.array([[2, 6, 3, 1], [1, 2, 3, 4]])\n",
    "print(P)\n",
    "print(f'The dimensions of P are: {P.shape}')\n",
    "print(Q, Q.shape)\n",
    "print(f'The dimensions of Q are: {Q.shape}')\n",
    "print(np.dot(P, Q))\n",
    "print(f'The dimensions of PxQ are: {np.dot(P, Q).shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8bc9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#what will happend here? \n",
    "np.dot(P, Q)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "797ad9f0",
   "metadata": {},
   "source": [
    "The **determinant** is an important property of square matrices (same number of rows and columns). The determinant is denoted by $\\det(M)$ or $|M|$.\n",
    "\n",
    "In the case of $2 \\times 2$ matrices, the determinant is \n",
    "$$\n",
    "\\begin{split}\n",
    "|M| = \\begin{bmatrix}\n",
    "a & b \\\\\n",
    "c & d\\\\\n",
    "\\end{bmatrix} = ad - bc\\end{split}\n",
    "$$\n",
    "\n",
    "\n",
    "In the case of $3 \\times 3$ matrices, the determinant is \n",
    "$$\n",
    "\\begin{split}\n",
    "\\begin{eqnarray*}\n",
    "|M| = \\begin{bmatrix}\n",
    "a & b & c \\\\\n",
    "d & e & f \\\\\n",
    "g & h & i \\\\\n",
    "\\end{bmatrix} & = & a\\begin{bmatrix}\n",
    "\\Box &\\Box  &\\Box  \\\\\n",
    "\\Box & e & f \\\\\n",
    "\\Box & h & i \\\\\n",
    "\\end{bmatrix} - b\\begin{bmatrix}\n",
    "\\Box &\\Box  &\\Box  \\\\\n",
    "d & \\Box & f \\\\\n",
    "g & \\Box & i \\\\\n",
    "\\end{bmatrix}+c\\begin{bmatrix}\n",
    "\\Box &\\Box  &\\Box  \\\\\n",
    "d & e & \\Box \\\\\n",
    "g & h & \\Box \\\\\n",
    "\\end{bmatrix} \\\\\n",
    "&&\\\\\n",
    "& = & a\\begin{bmatrix}\n",
    "e & f \\\\\n",
    "h & i \\\\\n",
    "\\end{bmatrix} - b\\begin{bmatrix}\n",
    "d & f \\\\\n",
    "g & i \\\\\n",
    "\\end{bmatrix}+c\\begin{bmatrix}\n",
    "d & e \\\\\n",
    "g & h \\\\\n",
    "\\end{bmatrix} \\\\ \n",
    "&&\\\\\n",
    "& = & aei + bfg + cdh - ceg - bdi - afh\n",
    "\\end{eqnarray*}\\end{split}\n",
    "$$\n",
    "\n",
    "\n",
    "Computing the determinant or larger matrices is cumbersome. However, the process can be easily automated and always reduced to computing the determinant of $2 \\time 2$ matrices. Numpy includes an efficient method to compute the determinant of a matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d7f84569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M: [[0 2 1 3]\n",
      " [3 2 8 1]\n",
      " [1 0 0 3]\n",
      " [0 3 2 1]]\n",
      "Determinant: -38.00\n"
     ]
    }
   ],
   "source": [
    "from numpy.linalg import det\n",
    "\n",
    "M = np.array([[0,2,1,3], \n",
    "             [3,2,8,1], \n",
    "             [1,0,0,3],\n",
    "             [0,3,2,1]])\n",
    "print(f'M: {M}')\n",
    "\n",
    "print(f'Determinant: {det(M):0.2f}') #note that the :0.2f limits the number of decimals printed!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a26cea2",
   "metadata": {},
   "source": [
    "The inverse of a square matrix $M$ is a matrix of the same size, $N$, such that $M \\bullet N=I$, Where $I$ is a matrix with only ones in its diagonal (unity matrix). The inverse of a matrix $M$ is denoted as $M^{-1}$. For a $2 \\times 2$ matrix, the inverse is defined as \n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "M^{-1} = \\begin{bmatrix}\n",
    "a & b \\\\\n",
    "c & d\\\\\n",
    "\\end{bmatrix}^{-1} = \\frac{1}{|M|}\\begin{bmatrix}\n",
    "d & -b \\\\\n",
    "-c & a\\\\\n",
    "\\end{bmatrix}\\end{split}\n",
    "$$\n",
    "\n",
    "calculating the inverse of a matrix is a complex process; however, it is an important step in many calculations and several *easier* approaches have been developed.\n",
    "\n",
    "if the determinant of a matrix is zero, then the matrix doesn't have an inverse. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "26309117",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M: [[0 2 1 3]\n",
      " [3 2 8 1]\n",
      " [1 0 0 3]\n",
      " [0 3 2 1]]\n",
      "Inverse: [[-1.57894737 -0.07894737  1.23684211  1.10526316]\n",
      " [-0.63157895 -0.13157895  0.39473684  0.84210526]\n",
      " [ 0.68421053  0.18421053 -0.55263158 -0.57894737]\n",
      " [ 0.52631579  0.02631579 -0.07894737 -0.36842105]]\n",
      "M x inv(M) = [[ 1.00000000e+00 -3.46944695e-18  5.55111512e-17  1.11022302e-16]\n",
      " [ 0.00000000e+00  1.00000000e+00  4.99600361e-16 -1.11022302e-16]\n",
      " [ 2.22044605e-16  5.20417043e-17  1.00000000e+00 -3.33066907e-16]\n",
      " [ 0.00000000e+00  1.73472348e-17  5.55111512e-17  1.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "from numpy.linalg import inv\n",
    "\n",
    "M = np.array([[0,2,1,3], \n",
    "             [3,2,8,1], \n",
    "             [1,0,0,3],\n",
    "             [0,3,2,1]])\n",
    "print(f'M: {M}')\n",
    "\n",
    "print(f'Inverse: {inv(M)}') #note that the :0.2f limits the number of decimals printed!\n",
    "\n",
    "print(f'M x inv(M) = {np.dot(M,inv(M))}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "308407c6",
   "metadata": {},
   "source": [
    "A matrix that is close to being singular (i.e., the determinant is close to 0) is called **ill-conditioned**. Although ill-conditioned matrices have inverses, they are problematic numerically in the same way that dividing a number by a very, very small number is problematic. \n",
    "The **condition number** is a measure of how ill-conditioned a matrix is, and it can be computed using Numpy’s function cond from linalg. The higher the condition number, the closer the matrix is to being singular.\n",
    "\n",
    "The **rank** of an $m \\times n$ matrix $A$ is the number of linearly independent columns or rows of $A$ (that is, you cannot write a row or column as a linear combination of other rows or columns), and is denoted by **rank(A)**. It can be shown that the number of linearly independent rows is always equal to the number of linearly independent columns for any matrix. A matrix is called full rank. if **rank (A)=min(m,n)**. The matrix, $A$, is also full rank if all of its columns are linearly independent.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a51b8048",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Condition number: 4.048917339522305\n",
      "Rank: 3\n"
     ]
    }
   ],
   "source": [
    "from numpy.linalg import cond, matrix_rank\n",
    "\n",
    "A = np.array([[1,1,0],\n",
    "              [0,1,0],\n",
    "              [1,0,1]])\n",
    "\n",
    "print(f'Condition number: {cond(A)}')\n",
    "print(f'Rank: {matrix_rank(A)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b9f6e6",
   "metadata": {},
   "source": [
    "if you append a new columns (or row) to a matrix, the rank will increase if the new columns add new information (that is, the new column cannot be explained by a linear combinantion of existing columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b247361e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmented matrix: \n",
      " [[1 1 0 1]\n",
      " [0 1 0 2]\n",
      " [1 0 1 1]]\n",
      "Rank of augmented matrix: 3 \n"
     ]
    }
   ],
   "source": [
    "y = np.array([[1], [2], [1]])\n",
    "A_y = np.concatenate((A, y), axis = 1)\n",
    "print(f'Augmented matrix: \\n {A_y}')\n",
    "print(f'Rank of augmented matrix: {matrix_rank(A_y)} ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc4c44a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
